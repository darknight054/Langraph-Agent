# OpenAI API Key (Required for OpenAI embeddings and contextual chunking)
# Can be omitted if using HuggingFace embeddings with semantic chunking
OPENAI_API_KEY=sk-...

# Embedding Configuration
# Provider: "openai" (requires OPENAI_API_KEY) or "huggingface" (local, no API needed)
EMBEDDING_PROVIDER=huggingface
# Model: OpenAI model name (e.g., "text-embedding-3-small") or HuggingFace model ID
EMBEDDING_MODEL=Qwen/Qwen3-Embedding-0.6B

# DeepSeek OCR Server (Required for OCR)
DEEPSEEK_OCR_URL=http://localhost:8000

# Vector Store
CHROMA_PERSIST_DIR=./chroma_db

# Langfuse Observability (Optional - project works without this)
# To enable: install with `uv sync --extra observability` and set these keys
# Sign up at https://cloud.langfuse.com or self-host
# LANGFUSE_PUBLIC_KEY=pk-...
# LANGFUSE_SECRET_KEY=sk-...
# LANGFUSE_HOST=https://cloud.langfuse.com

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=console  # "json" for production, "console" for development

# Chunking Configuration
CHUNK_SIZE=512
CHUNK_OVERLAP=50
# Strategy: "semantic" (fast, good baseline) or "contextual" (slower, 49% better retrieval)
CHUNKING_STRATEGY=semantic

# RAG Configuration
RETRIEVAL_TOP_K=5
MAX_RETRY_COUNT=3
